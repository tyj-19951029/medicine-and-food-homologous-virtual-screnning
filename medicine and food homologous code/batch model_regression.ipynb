{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QSAR_package.data_split import extractData,randomSpliter\n",
    "from QSAR_package.feature_preprocess import correlationSelection,RFE_ranking\n",
    "from QSAR_package.data_scale import dataScale\n",
    "from QSAR_package.grid_search import gridSearchPlus,gridSearchBase\n",
    "from QSAR_package.model_evaluation import modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8个特征，第1/2次gridsearch，此轮耗时00h:01m:00s\n",
      "8个特征，第2/2次gridsearch，此轮耗时00h:00m:55s\n",
      "9个特征，第1/2次gridsearch，此轮耗时00h:00m:54s\n",
      "9个特征，第2/2次gridsearch，此轮耗时00h:00m:48s\n",
      "10个特征，第1/2次gridsearch，此轮耗时00h:00m:53s\n",
      "10个特征，第2/2次gridsearch，此轮耗时00h:00m:49s\n",
      "11个特征，第1/2次gridsearch，此轮耗时00h:00m:52s\n",
      "11个特征，第2/2次gridsearch，此轮耗时00h:00m:50s\n",
      "12个特征，第1/2次gridsearch，此轮耗时00h:00m:50s\n",
      "12个特征，第2/2次gridsearch，此轮耗时00h:00m:49s\n",
      "13个特征，第1/2次gridsearch，此轮耗时00h:00m:46s\n",
      "13个特征，第2/2次gridsearch，此轮耗时00h:00m:46s\n",
      "14个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "14个特征，第2/2次gridsearch，此轮耗时00h:00m:42s\n",
      "15个特征，第1/2次gridsearch，此轮耗时00h:00m:42s\n",
      "15个特征，第2/2次gridsearch，此轮耗时00h:00m:46s\n",
      "16个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "16个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "17个特征，第1/2次gridsearch，此轮耗时00h:00m:45s\n",
      "17个特征，第2/2次gridsearch，此轮耗时00h:00m:45s\n",
      "18个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "18个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "19个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "19个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "20个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "20个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "21个特征，第1/2次gridsearch，此轮耗时00h:00m:45s\n",
      "21个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "22个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "22个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "23个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "23个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "24个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "24个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "25个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "25个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "26个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "26个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "27个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "27个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "28个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "28个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "29个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "29个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "30个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "30个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "31个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "31个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "32个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "32个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "33个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "33个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "34个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "34个特征，第2/2次gridsearch，此轮耗时00h:00m:44s\n",
      "35个特征，第1/2次gridsearch，此轮耗时00h:00m:44s\n",
      "35个特征，第2/2次gridsearch，此轮耗时00h:00m:45s\n",
      "36个特征，第1/2次gridsearch，此轮耗时00h:00m:43s\n",
      "36个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "37个特征，第1/2次gridsearch，此轮耗时00h:00m:45s\n",
      "37个特征，第2/2次gridsearch，此轮耗时00h:00m:46s\n",
      "38个特征，第1/2次gridsearch，此轮耗时00h:00m:45s\n",
      "38个特征，第2/2次gridsearch，此轮耗时00h:00m:47s\n",
      "39个特征，第1/2次gridsearch，此轮耗时00h:00m:47s\n",
      "39个特征，第2/2次gridsearch，此轮耗时00h:00m:47s\n",
      "40个特征，第1/2次gridsearch，此轮耗时00h:00m:45s\n",
      "40个特征，第2/2次gridsearch，此轮耗时00h:00m:42s\n",
      "33×2次gridsearch执行完毕，总耗时00h:50m:23s，可通过best_params属性查看最优参数，通过cv_results属性查看所有结果\n",
      "Training results: \u001b[1m{'r2': 0.2454, 'rmse': 0.193, 'mae': 0.1506}\u001b[0m\n",
      "Test results: \u001b[1m{'r2': -0.32, 'rmse': 0.2625, 'mae': 0.1797}\u001b[0m\n",
      "\u001b[1m        r2    rmse     mae\n",
      "tr  0.2454  0.1930  0.1506\n",
      "te -0.3200  0.2625  0.1797\n",
      "cv  0.1339  0.2067  0.1619\u001b[0m\n",
      "模型的结果已保存至\u001b[1mD:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som_results.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TYJ\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "8个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "9个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "9个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "10个特征，第1/2次gridsearch，此轮耗时00h:00m:06s\n",
      "10个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "11个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "11个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "12个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "12个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "13个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "13个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "14个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "14个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "15个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "15个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "16个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "16个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "17个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "17个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "18个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "18个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "19个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "19个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "20个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "20个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "21个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "21个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "22个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "22个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "23个特征，第1/2次gridsearch，此轮耗时00h:00m:09s\n",
      "23个特征，第2/2次gridsearch，此轮耗时00h:00m:09s\n",
      "24个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "24个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "25个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "25个特征，第2/2次gridsearch，此轮耗时00h:00m:09s\n",
      "26个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "26个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "27个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "27个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "28个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "28个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "29个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "29个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "30个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "30个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "31个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "31个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "32个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "32个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "33个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "33个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "34个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "34个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "35个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "35个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "36个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "36个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "37个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "37个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "38个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "38个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "39个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "39个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "40个特征，第1/2次gridsearch，此轮耗时00h:00m:13s\n",
      "40个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "33×2次gridsearch执行完毕，总耗时00h:10m:48s，可通过best_params属性查看最优参数，通过cv_results属性查看所有结果\n",
      "Training results: \u001b[1m{'r2': 0.6495, 'rmse': 0.1315, 'mae': 0.1084}\u001b[0m\n",
      "Test results: \u001b[1m{'r2': -0.0708, 'rmse': 0.2365, 'mae': 0.17}\u001b[0m\n",
      "\u001b[1m        r2    rmse     mae\n",
      "tr  0.6495  0.1315  0.1084\n",
      "te -0.0708  0.2365  0.1700\n",
      "cv  0.0406  0.2176  0.1730\u001b[0m\n",
      "模型的结果已保存至\u001b[1mD:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som_results.csv\u001b[0m\n",
      "8个特征，第1/2次gridsearch，此轮耗时00h:00m:42s\n",
      "8个特征，第2/2次gridsearch，此轮耗时00h:00m:43s\n",
      "9个特征，第1/2次gridsearch，此轮耗时00h:00m:42s\n",
      "9个特征，第2/2次gridsearch，此轮耗时00h:00m:42s\n",
      "10个特征，第1/2次gridsearch，此轮耗时00h:00m:41s\n",
      "10个特征，第2/2次gridsearch，此轮耗时00h:00m:40s\n",
      "11个特征，第1/2次gridsearch，此轮耗时00h:00m:40s\n",
      "11个特征，第2/2次gridsearch，此轮耗时00h:00m:40s\n",
      "12个特征，第1/2次gridsearch，此轮耗时00h:00m:39s\n",
      "12个特征，第2/2次gridsearch，此轮耗时00h:00m:39s\n",
      "13个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "13个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "14个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "14个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "15个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "15个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "16个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "16个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "17个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "17个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "18个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "18个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "19个特征，第1/2次gridsearch，此轮耗时00h:00m:38s\n",
      "19个特征，第2/2次gridsearch，此轮耗时00h:00m:38s\n",
      "20个特征，第1/2次gridsearch，此轮耗时00h:00m:37s\n",
      "20个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "21个特征，第1/2次gridsearch，此轮耗时00h:00m:37s\n",
      "21个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "22个特征，第1/2次gridsearch，此轮耗时00h:00m:37s\n",
      "22个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "23个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "23个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "24个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "24个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "25个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "25个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "26个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "26个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "27个特征，第1/2次gridsearch，此轮耗时00h:00m:37s\n",
      "27个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "28个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "28个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "29个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "29个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "30个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "30个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "31个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "31个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "32个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "32个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "33个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "33个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "34个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "34个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "35个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "35个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "36个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "36个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "37个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "37个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "38个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "38个特征，第2/2次gridsearch，此轮耗时00h:00m:36s\n",
      "39个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "39个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "40个特征，第1/2次gridsearch，此轮耗时00h:00m:36s\n",
      "40个特征，第2/2次gridsearch，此轮耗时00h:00m:37s\n",
      "33×2次gridsearch执行完毕，总耗时00h:41m:37s，可通过best_params属性查看最优参数，通过cv_results属性查看所有结果\n",
      "Training results: \u001b[1m{'r2': 0.3113, 'rmse': 0.1843, 'mae': 0.1458}\u001b[0m\n",
      "Test results: \u001b[1m{'r2': -0.0254, 'rmse': 0.2314, 'mae': 0.1702}\u001b[0m\n",
      "\u001b[1m        r2    rmse     mae\n",
      "tr  0.3113  0.1843  0.1458\n",
      "te -0.0254  0.2314  0.1702\n",
      "cv  0.0892  0.2120  0.1668\u001b[0m\n",
      "模型的结果已保存至\u001b[1mD:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som_results.csv\u001b[0m\n",
      "8个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "8个特征，第2/2次gridsearch，此轮耗时00h:00m:07s\n",
      "9个特征，第1/2次gridsearch，此轮耗时00h:00m:07s\n",
      "9个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "10个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "10个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "11个特征，第1/2次gridsearch，此轮耗时00h:00m:08s\n",
      "11个特征，第2/2次gridsearch，此轮耗时00h:00m:08s\n",
      "12个特征，第1/2次gridsearch，此轮耗时00h:00m:09s\n",
      "12个特征，第2/2次gridsearch，此轮耗时00h:00m:09s\n",
      "13个特征，第1/2次gridsearch，此轮耗时00h:00m:09s\n",
      "13个特征，第2/2次gridsearch，此轮耗时00h:00m:09s\n",
      "14个特征，第1/2次gridsearch，此轮耗时00h:00m:09s\n",
      "14个特征，第2/2次gridsearch，此轮耗时00h:00m:09s\n",
      "15个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "15个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "16个特征，第1/2次gridsearch，此轮耗时00h:00m:10s\n",
      "16个特征，第2/2次gridsearch，此轮耗时00h:00m:10s\n",
      "17个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "17个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "18个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "18个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "19个特征，第1/2次gridsearch，此轮耗时00h:00m:11s\n",
      "19个特征，第2/2次gridsearch，此轮耗时00h:00m:11s\n",
      "20个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "20个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "21个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "21个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "22个特征，第1/2次gridsearch，此轮耗时00h:00m:12s\n",
      "22个特征，第2/2次gridsearch，此轮耗时00h:00m:12s\n",
      "23个特征，第1/2次gridsearch，此轮耗时00h:00m:13s\n",
      "23个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "24个特征，第1/2次gridsearch，此轮耗时00h:00m:13s\n",
      "24个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "25个特征，第1/2次gridsearch，此轮耗时00h:00m:13s\n",
      "25个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "26个特征，第1/2次gridsearch，此轮耗时00h:00m:13s\n",
      "26个特征，第2/2次gridsearch，此轮耗时00h:00m:13s\n",
      "27个特征，第1/2次gridsearch，此轮耗时00h:00m:14s\n",
      "27个特征，第2/2次gridsearch，此轮耗时00h:00m:14s\n",
      "28个特征，第1/2次gridsearch，此轮耗时00h:00m:14s\n",
      "28个特征，第2/2次gridsearch，此轮耗时00h:00m:14s\n",
      "29个特征，第1/2次gridsearch，此轮耗时00h:00m:14s\n",
      "29个特征，第2/2次gridsearch，此轮耗时00h:00m:14s\n",
      "30个特征，第1/2次gridsearch，此轮耗时00h:00m:14s\n",
      "30个特征，第2/2次gridsearch，此轮耗时00h:00m:14s\n",
      "31个特征，第1/2次gridsearch，此轮耗时00h:00m:15s\n",
      "31个特征，第2/2次gridsearch，此轮耗时00h:00m:15s\n",
      "32个特征，第1/2次gridsearch，此轮耗时00h:00m:15s\n",
      "32个特征，第2/2次gridsearch，此轮耗时00h:00m:15s\n",
      "33个特征，第1/2次gridsearch，此轮耗时00h:00m:15s\n",
      "33个特征，第2/2次gridsearch，此轮耗时00h:00m:15s\n",
      "34个特征，第1/2次gridsearch，此轮耗时00h:00m:15s\n",
      "34个特征，第2/2次gridsearch，此轮耗时00h:00m:16s\n",
      "35个特征，第1/2次gridsearch，此轮耗时00h:00m:17s\n",
      "35个特征，第2/2次gridsearch，此轮耗时00h:00m:17s\n",
      "36个特征，第1/2次gridsearch，此轮耗时00h:00m:16s\n",
      "36个特征，第2/2次gridsearch，此轮耗时00h:00m:16s\n",
      "37个特征，第1/2次gridsearch，此轮耗时00h:00m:16s\n",
      "37个特征，第2/2次gridsearch，此轮耗时00h:00m:16s\n",
      "38个特征，第1/2次gridsearch，此轮耗时00h:00m:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38个特征，第2/2次gridsearch，此轮耗时00h:00m:17s\n",
      "39个特征，第1/2次gridsearch，此轮耗时00h:00m:17s\n",
      "39个特征，第2/2次gridsearch，此轮耗时00h:00m:17s\n",
      "40个特征，第1/2次gridsearch，此轮耗时00h:00m:17s\n",
      "40个特征，第2/2次gridsearch，此轮耗时00h:00m:17s\n",
      "33×2次gridsearch执行完毕，总耗时00h:14m:25s，可通过best_params属性查看最优参数，通过cv_results属性查看所有结果\n",
      "Training results: \u001b[1m{'r2': 0.6465, 'rmse': 0.1321, 'mae': 0.1074}\u001b[0m\n",
      "Test results: \u001b[1m{'r2': 0.0467, 'rmse': 0.2231, 'mae': 0.1688}\u001b[0m\n",
      "\u001b[1m        r2    rmse     mae\n",
      "tr  0.6465  0.1321  0.1074\n",
      "te  0.0467  0.2231  0.1688\n",
      "cv  0.0924  0.2116  0.1637\u001b[0m\n",
      "模型的结果已保存至\u001b[1mD:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som_results.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "spliter =extractData()\n",
    "file=r'D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som.csv'\n",
    "acc_path = r\"D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_337_som_acc.csv\"\n",
    "spliter.ExtractTrainTestData(r\"D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\tr_252.csv\",\n",
    "                             r\"D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\te_85.csv\",label_name='label')\n",
    "tr_x = spliter.tr_x\n",
    "tr_y = spliter.tr_y\n",
    "te_y = spliter.te_y\n",
    "\n",
    "corr = correlationSelection()\n",
    "corr.PearsonXX(tr_x, tr_y)\n",
    "randx='som'\n",
    "scaler = dataScale(scale_range=(0.1, 0.9))\n",
    "\n",
    "tr_scaled_x = scaler.FitTransform(corr.selected_tr_x.iloc[:,:])\n",
    "te_scaled_x = scaler.Transform(spliter.te_x,DataSet='test')\n",
    "\n",
    "for rankN in ['SVR','RFR']: \n",
    "    if rankN == 'Person':\n",
    "        tr_ranked_x = tr_scaled_x\n",
    "        te_ranked_x = te_scaled_x\n",
    "        notes1 = 'Person'\n",
    "    else:\n",
    "        rfe = RFE_ranking(rankN,features_num=1)\n",
    "        rfe.Fit(tr_scaled_x, tr_y)\n",
    "        tr_ranked_x = rfe.tr_ranked_x\n",
    "        te_ranked_x = te_scaled_x.loc[:,tr_ranked_x.columns]\n",
    "        notes1 = rankN+'-RFE'\n",
    "\n",
    "    for estimatorName in ['SVR','RFR']:\n",
    "        grid = gridSearchPlus(grid_estimatorName=estimatorName, fold=5, repeat=2,scoreThreshold=-0.6)\n",
    "        grid.FitWithFeaturesNum(tr_ranked_x, tr_y,features_range=(8,41))   # 用RFE排序\n",
    "        # grid.FitWithFeaturesNum(tr_scaled_x, tr_y,features_range=(5,23))      # 用pearson相关性排序\n",
    "        \n",
    "        model = modeling(grid.best_estimator,params=grid.best_params)\n",
    "        model.Fit(tr_scaled_x.loc[:,grid.best_features], tr_y)\n",
    "        model.Predict(te_scaled_x.loc[:,grid.best_features],te_y)\n",
    "        model.CrossVal(cv='LOO')\n",
    "        tr_pred = model.tr_pred_y\n",
    "        te_pred = model.te_pred_y\n",
    "        pred_results = pd.DataFrame([tr_y.values,tr_pred,te_y.values,te_pred],\n",
    "                                    index=['tr_y','tr_pred','te_y','te_pred']).T\n",
    "        path = r\"D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_RDK_pred_{}_{}_{}.csv\".format(randx,notes1,estimatorName)\n",
    "        pred_results.to_csv(path,index=False)\n",
    "        with open(r\"D:\\academic\\01_degree_doctor\\01_project\\mPGES\\06_QSAR\\C2_337\\som\\C2_RDK_des_{}_{}_{}.csv\".format(notes1,randx,estimatorName),'w') as fobj:\n",
    "            fobj.write('\\n'.join(grid.best_features))\n",
    "        model.ShowResults(show_cv=True,make_fig=False)\n",
    "        model.SaveResults(file[:-4]+'_results.csv',notes='{},split_seed={},gridCV=5'.format(notes1,randx),save_model=True)\n",
    "        tr_pred = pred_results.tr_pred\n",
    "        te_pred = pred_results.te_pred\n",
    "        tr_true = pred_results.tr_y\n",
    "        te_true = pred_results.te_y\n",
    "        pred_results[\"tr_abs_error\"] = abs(tr_true - tr_pred)\n",
    "        pred_results[\"te_abs_error\"] = abs(te_true - te_pred).dropna(how=\"all\")\n",
    "        tr_rmse = model.tr_evaluator.rmse\n",
    "        te_rmse = model.te_evaluator.rmse\n",
    "        tr_count = len(pred_results.tr_abs_error.where(pred_results.tr_abs_error < tr_rmse).dropna(how=\"all\"))\n",
    "        te_count = len(pred_results.te_abs_error.where(pred_results.te_abs_error < te_rmse).dropna(how=\"all\"))\n",
    "        tr_acc = round(tr_count/len(abs(tr_true - tr_pred)), 4)\n",
    "        te_acc = round(te_count/len(abs(te_true - te_pred).dropna(how=\"all\")), 4)\n",
    "        with open(acc_path, \"a+\", newline='') as f:\n",
    "            csv_write = csv.writer(f)\n",
    "            data_row = [tr_acc, te_acc]\n",
    "            csv_write.writerow(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from QSAR_package.data_split import extractData, randomSpliter\n",
    "from QSAR_package.feature_preprocess import correlationSelection\n",
    "from QSAR_package.data_scale import dataScale\n",
    "from QSAR_package.model_evaluation import modelEvaluator\n",
    "from time import time\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sec2Time(seconds):  # convert seconds to time\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return (\"{:02d}h:{:02d}m:{:02d}s\".format(h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, c='b',lw=1,label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, c='r',lw=1,label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        print('Training complete')\n",
    "#         plt.plot(self.x, self.losses, c='b',lw=0.8,label=\"training loss\")\n",
    "#         plt.plot(self.x, self.val_losses, c='r',lw=0.8,ls='-.',label=\"validation loss\")\n",
    "#         plt.ylabel('Loss',fontproperties='Times New Roman',fontsize=13)\n",
    "#         plt.xlabel('Epoch',fontproperties='Times New Roman',fontsize=13)\n",
    "#         plt.title('Model Prediction Loss (CrossEntropy)',fontproperties='Arial',\n",
    "#                   fontsize=15,fontstyle='normal')\n",
    "#         plt.legend()\n",
    "#         plt.savefig('./cox-2/loss_fig.tif',dpi=300,bbox_inches='tight')\n",
    "#         plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter =extractData()\n",
    "spliter.ExtractTrainTestData(\"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/tr_929.csv\",\n",
    "                             \"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/te_309.csv\",label_name='pValue')\n",
    "\n",
    "tr_x = spliter.tr_x\n",
    "tr_y = spliter.tr_y\n",
    "te_y = spliter.te_y\n",
    "corr = correlationSelection()\n",
    "corr.PearsonXX(tr_x, tr_y)\n",
    "\n",
    "randx='reset'\n",
    "scaler = dataScale(scale_range=(0.1, 0.9))\n",
    "tr_scaled_x = scaler.FitTransform(corr.selected_tr_x)\n",
    "\n",
    "te_scaled_x = scaler.Transform(spliter.te_x,DataSet='test')\n",
    "print('train: {}\\ntest: {}'.format(len(tr_scaled_x),len(te_scaled_x)))\n",
    "rs = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "rs.get_n_splits(tr_y)\n",
    "tr_idxs = []\n",
    "va_idxs = []\n",
    "for train_index, test_index in rs.split(tr_y):\n",
    "    tr_idxs.append(train_index)\n",
    "    va_idxs.append(test_index)\n",
    "try:\n",
    "    result = pd.read_csv(\"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_result{}.csv\".format(randx))\n",
    "    max_r2 = result.te_r2[0]\n",
    "except:\n",
    "    max_r2 = 0.5\n",
    "for i in range(50):\n",
    "    tf.keras.backend.clear_session()\n",
    "    t0 = time()\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(units=50,activation='relu',name='Layer1',input_shape=(tr_scaled_x.shape[1],)))\n",
    "    model.add(layers.Dense(units=50,activation='relu',name='Layer2'))\n",
    "    model.add(layers.Dense(units=50,activation='relu',name='Layer3'))\n",
    "    model.add(layers.Dense(units=1,activation='relu',name='OutputLayer'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0005),\n",
    "                 loss='mse',metrics=['mae'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0,patience=30, verbose=0,mode='auto')\n",
    "\n",
    "    history = []\n",
    "    val_pred = []\n",
    "    val_y = []\n",
    "    for i in range(len(tr_idxs)):\n",
    "        tr_x_input = tr_scaled_x.iloc[tr_idxs[i],:].values\n",
    "        tr_y_input = tr_y.iloc[tr_idxs[i]].values\n",
    "        va_x_input = tr_scaled_x.iloc[va_idxs[i],:].values\n",
    "        va_y_input = tr_y.iloc[va_idxs[i]].values\n",
    "        history.append(model.fit(x=tr_x_input,y=tr_y_input,epochs=1000,validation_data=(va_x_input,va_y_input),\n",
    "                            verbose=0,callbacks=[early_stopping,plot_losses]))\n",
    "        val_pred.extend(model.predict(x=va_x_input).flatten())\n",
    "        val_y.extend(va_y_input)\n",
    "        print(Sec2Time(time()-t0))\n",
    "\n",
    "    tr_pred = model.predict(x=tr_scaled_x.values).flatten()\n",
    "    # val_pred = model.predict(x=val_scaled_x.values).flatten()\n",
    "    te_pred = model.predict(x=te_scaled_x.values).flatten()\n",
    "\n",
    "    tr_Evaluator = modelEvaluator(tr_y, tr_pred)\n",
    "    val_Evaluator = modelEvaluator(val_y, val_pred)\n",
    "    te_Evaluator = modelEvaluator(te_y, te_pred)\n",
    "\n",
    "    if te_Evaluator.r2 > max_r2:\n",
    "        max_r2 = te_Evaluator.r2\n",
    "\n",
    "        print(tr_Evaluator.r2,tr_Evaluator.rmse)\n",
    "        print(val_Evaluator.r2,val_Evaluator.rmse)\n",
    "        print(te_Evaluator.r2,te_Evaluator.rmse)\n",
    "\n",
    "        pred_evaluation = pd.DataFrame([randx,tr_Evaluator.r2,tr_Evaluator.rmse,val_Evaluator.r2,val_Evaluator.rmse,\n",
    "                                        te_Evaluator.r2,te_Evaluator.rmse],\n",
    "                                      index=['split_seed','tr_r2','tr_mse','val_r2','val_mse','te_r2','te_mse']).T\n",
    "        path = \"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_result{}.csv\".format(randx)\n",
    "        pred_evaluation.to_csv(path,index=False)\n",
    "\n",
    "        pred_results = pd.DataFrame([tr_y.values,tr_pred,val_y,val_pred,te_y.values,te_pred],\n",
    "                                    index=['tr_y','tr_pred','val_y','val_pred','te_y','te_pred']).T\n",
    "        path =  \"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_pred_values_{}.csv\".format(randx)\n",
    "        pred_results.to_csv(path,index=False)\n",
    "\n",
    "        model.save( \"C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/model_rdkit_rgr_{}.h5\".format(randx))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        axisMin = min(tr_y.min(),te_y.min(),tr_pred.min(),te_pred.min())-0.5\n",
    "        axisMax = max(tr_y.max(),te_y.max(),tr_pred.max(),te_pred.max())+0.5\n",
    "        plt.plot(tr_y,tr_pred,'xb',markersize=8)\n",
    "        plt.plot(te_y,te_pred,'or',mfc='w',markersize=6)\n",
    "        plt.plot([axisMin,axisMax],[axisMin,axisMax],'k',lw=1)\n",
    "        plt.axis([axisMin,axisMax,axisMin,axisMax])\n",
    "        plt.xlabel('pKi values (true)',fontproperties='Times New Roman',fontsize=13)\n",
    "        plt.ylabel('pKi values (predict)',fontproperties='Times New Roman',fontsize=13)\n",
    "        plt.legend(['training set', 'test set'], loc='best')\n",
    "        plt.savefig('C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_scatter_fig_{}.tif'.format(randx),\n",
    "                    dpi=300,bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        tr_loss = []\n",
    "        va_loss = []\n",
    "        tr_loss_flat = []\n",
    "        va_loss_flat = []\n",
    "        for i in range(len(history)):\n",
    "            tr_loss.append(history[i].history['loss'])\n",
    "            va_loss.append(history[i].history['val_loss'])\n",
    "            tr_loss_flat.extend(history[i].history['loss'])\n",
    "            va_loss_flat.extend(history[i].history['val_loss'])\n",
    "\n",
    "        step = 0\n",
    "        flag = [0]\n",
    "        for i in range(len(tr_loss)-1):\n",
    "            step = step+len(tr_loss[i])\n",
    "            flag.append(step)\n",
    "        flag.append(len(tr_loss_flat))\n",
    "\n",
    "        tr_loss_df = pd.DataFrame(tr_loss,index=['fold_{}'.format(i+1) for i in range(len(tr_loss))]).T\n",
    "        val_loss_df = pd.DataFrame(va_loss,index=['fold_{}'.format(i+1) for i in range(len(va_loss))]).T\n",
    "\n",
    "        tr_loss_df.to_csv('C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_tr_loss_{}.csv'.format(randx),\n",
    "                          index=False)\n",
    "        val_loss_df.to_csv('C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/rdkit_val_loss_{}.csv'.format(randx),\n",
    "                           index=False)\n",
    "\n",
    "        h = 0.05\n",
    "        x_min = 0\n",
    "        x_max = len(tr_loss_flat)\n",
    "        y_min = min(tr_loss_flat)-1\n",
    "        y_max = max(tr_loss_flat)+1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "        Z = np.zeros_like(xx)\n",
    "\n",
    "        for i in range(len(flag)-1):\n",
    "            Z[np.where((flag[i]<xx)&(xx<=flag[i+1]))] = i+1\n",
    "\n",
    "        fig = plt.figure(figsize=(9,6))\n",
    "        plt.plot(tr_loss_flat,c='b',ls='solid',lw=0.8)\n",
    "        plt.plot(va_loss_flat,c='r',ls='-.',lw=0.8)\n",
    "        plt.imshow(Z, interpolation='nearest',alpha=0.5,\n",
    "                   extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                   cmap=plt.cm.Greys,\n",
    "                   aspect='auto', origin='lower')\n",
    "        plt.xlim(-10,x_max+5)\n",
    "        plt.ylim(0,2)\n",
    "        for i in range(len(flag)-1):\n",
    "            plt.text(np.average(flag[i:i+2]), 1, '{}th\\nfold'.format(i+1), fontsize=2,color='#FF00FF',\n",
    "                     fontproperties='Arial',rasterized=True,horizontalalignment='center')\n",
    "        plt.ylabel('Loss',fontproperties='Times New Roman',fontsize=13)\n",
    "        plt.xlabel('Epoch',fontproperties='Times New Roman',fontsize=13)\n",
    "        plt.legend(['training loss', 'validation loss'], loc=(0.05,0.87))\n",
    "        plt.savefig('C:/Users/zhangshd408/Desktop/recent_work/1238/reset_all/DL_results_rdkit_loss_fig_{}.tif'.format(randx),\n",
    "                    dpi=300,bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
